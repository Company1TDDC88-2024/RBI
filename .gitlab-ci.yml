---
stages:
    - cleanup
    - start_registry
    - build
    - test
    - pre-deploy
    - deploy

variables:
    DOCKER_DRIVER: overlay2
    LIU_COURSE_CODE: tddc88
    LIU_COURSE_TERM: ht24
    LIU_GROUP_NAME: company1
    LIU_PROJECT_HOST: ${LIU_COURSE_CODE}-${LIU_GROUP_NAME}-${LIU_COURSE_TERM}.kubernetes-public.it.liu.se
    POD_NAMESPACE: tddc88-ht24-company1
    DOCKER_HUB_REPOSITORY: companyonetddc
    FRONTEND_IMAGE: $DOCKER_HUB_REPOSITORY/frontend:latest
    BACKEND_IMAGE: $DOCKER_HUB_REPOSITORY/backend:latest
    DOCKER_USERNAME: companyonetddc
    DOCKER_REGISTRY: docker.io

clear_cache:
    stage: cleanup
    script:
        - echo "Clearing cache..."
        - rm -rf path/to/cache
    rules:
        - when: always # Always run this job to clear cache

build_frontend:
    stage: build
    image: buildah # Use Buildah image
    script:
        - echo "$DOCKER_PASSWORD" | buildah login -u "$DOCKER_USERNAME" --password-stdin $DOCKER_REGISTRY # Login to Docker Hub
        - export _BUILDAH_STARTED_IN_USERNS='' # Allow Buildah to run without user namespace
        - export BUILDAH_ISOLATION=chroot # Isolation mode for Buildah
        - export STORAGE_DRIVER=vfs # Use vfs storage driver
        - export BUILDAH_FORMAT=docker # Use Docker image format
        - cd Frontend
        - buildah build-using-dockerfile --tag "$FRONTEND_IMAGE" . # Build the frontend image
        - buildah push "$FRONTEND_IMAGE" # Push the image to Docker Hub

build_backend:
    stage: build
    image: buildah
    script:
        - echo "$DOCKER_PASSWORD" | buildah login -u "$DOCKER_USERNAME" --password-stdin $DOCKER_REGISTRY # Login to Docker Hub
        - export _BUILDAH_STARTED_IN_USERNS='' # Allow Buildah to run without user namespace
        - export BUILDAH_ISOLATION=chroot # Isolation mode for Buildah
        - export STORAGE_DRIVER=vfs
        - export BUILDAH_FORMAT=docker # Use Docker image format
        - cd Backend
        - buildah build-using-dockerfile --tag "$BACKEND_IMAGE" . # Build the backend image
        - buildah push "$BACKEND_IMAGE" # Push the image to Docker Hub

test:
    stage: test
    image: python:3.12-slim # Use Python image that has pytest installed
    before_script:
        - cd Backend
        - pip install poetry # Ensure poetry is installed
        - apt-get update && apt-get install -y unixodbc-dev
        - poetry install # Install dependencies
        - pip install python-dotenv # Install dotenv to load .env file
        - pip install pytest # Install pytest
        - pip install pytest-html
        - pip install pyodbc
        - export $(cat .env | xargs) # Load environment variables from .env (if necessary)
    script:
        - cd AutoTesting
        - poetry run pytest --maxfail=1 --disable-warnings -q
    allow_failure: false # Ensure the pipeline stops if tests fail

test_database_connection:
    stage: test
    image: busybox
    script:
        - nslookup tddc88company1.database.windows.net

retrieve kubeconfig:
    stage: pre-deploy
    image: bitnami/kubectl
    before_script:
        - kubectl config use-context tddc88-ht24/infrastructure:tddc88-ht24
    script:
        - TOKEN_DATA=$(kubectl get secret admin-user-token -o json)
        - CA=$(echo "$TOKEN_DATA" | jq '.data."ca.crt"' -r | base64 -d)
        - TOKEN=$(echo "$TOKEN_DATA" | jq '.data.token' -r | base64 -d)
        - |
            cat << EOF # Store this generated kubeconfig as .kube/config
            ---
            apiVersion: v1
            clusters:
            - cluster:
                server: https://tddc88-ht24.course.kubernetes.it.liu.se/
                certificate-authority-data: $(echo "$CA" | base64 -w0)
              name: tddc88
            contexts:
            - context:
                cluster: 
                namespace: $POD_NAMESPACE
                user: tddc88
              name: tddc88
            current-context: tddc88
            kind: Config
            preferences: {}
            users:
            - name: tddc88
              user:
                token: $TOKEN
            EOF

deploy:
    stage: deploy
    rules:
        - if: '$CI_COMMIT_BRANCH == "main"'
        - if: '$CI_COMMIT_BRANCH == "Development"'
    image: bitnami/kubectl
    before_script:
        - kubectl config use-context tddc88-ht24/infrastructure:tddc88-ht24
    script:
        - kubectl delete deployment frontend-deployment --ignore-not-found
        - kubectl delete deployment backend-deployment --ignore-not-found
        - kubectl delete service frontend-service --ignore-not-found
        - kubectl delete service backend-service --ignore-not-found
        - kubectl delete ingress app-ingress -n tddc88-ht24-company1 --ignore-not-found
        - kubectl delete deployment redis --ignore-not-found
        - kubectl delete service redis --ignore-not-found
        # Wait for frontend deployment to be deleted
        - kubectl wait --for=delete deployment/frontend-deployment --timeout=60s || echo "Frontend deployment already deleted or timed out"

        # Wait for backend deployment to be deleted
        - kubectl wait --for=delete deployment/backend-deployment --timeout=60s || echo "Backend deployment already deleted or timed out"

        # Wait for frontend service to be deleted
        - kubectl wait --for=delete service/frontend-service --timeout=60s || echo "Frontend service already deleted or timed out"

        # Wait for backend service to be deleted
        - kubectl wait --for=delete service/backend-service --timeout=60s || echo "Backend service already deleted or timed out"

        # Wait for ingress to be deleted
        - kubectl wait --for=delete ingress app-ingress -n tddc88-ht24-company1 --timeout=60s || echo "Ingress already deleted or timed out"

        #- kubectl apply -f k8s/resource-quota.yml
        - echo "Deploying frontend to Kubernetes..."
        - kubectl apply -f k8s/FE-deployment.yml
        - kubectl apply -f k8s/FE-service.yml
        - kubectl apply -f k8s/redis-deployment.yml
        - kubectl apply -f k8s/redis-service.yml
        - kubectl get pods
        - kubectl get deployment frontend-deployment
        - sleep 15
        - kubectl describe deployment frontend-deployment
        - kubectl get events --sort-by='.metadata.creationTimestamp'
        - POD_NAME=$(kubectl get pods -l app=frontend -o jsonpath='{.items[0].metadata.name}')
        - echo "Waiting for pod $POD_NAME to be ready..."
        - echo $POD_NAME
        - kubectl describe pod $POD_NAME
        - kubectl get events --sort-by='.metadata.creationTimestamp'
        - kubectl wait --for=condition=ready pod/$POD_NAME --timeout=300s

        - echo "Deploying backend to Kubernetes..."
        - kubectl apply -f k8s/BE-deployment.yml
        - kubectl apply -f k8s/BE-service.yml
        - kubectl get pods
        - kubectl get deployment backend-deployment
        - sleep 10
        - POD_NAME=$(kubectl get pods -l app=backend -o jsonpath='{.items[0].metadata.name}')
        - echo "Waiting for pod $POD_NAME to be ready..."
        - echo $POD_NAME
        - kubectl describe pod $POD_NAME
        - kubectl get events --sort-by='.metadata.creationTimestamp'
        - kubectl wait --for=condition=ready pod/$POD_NAME --timeout=300s

        # Wait for backend to be ready
        - kubectl get pods
        - kubectl rollout status deployment/backend-deployment --timeout=600s
        - kubectl get pods

        # Wait for frontend to be ready
        - kubectl rollout status deployment/frontend-deployment --timeout=240s
        - kubectl get pods
        # Re-deploy backend

        # Apply ingress rules
        - kubectl apply -f k8s/ingress.yml
        - sleep 15
        - kubectl get svc -n tddc88-ht24-company1
        - POD_NAME=$(kubectl get pods -l app=backend -o jsonpath='{.items[0].metadata.name}')
        - POD_NAME_FE=$(kubectl get pods -l app=frontend -o jsonpath='{.items[0].metadata.name}')
        - kubectl describe ingress app-ingress -n tddc88-ht24-company1
        - kubectl get ingress -n tddc88-ht24-company1
        - INGRESS_NAME=$(kubectl get ingress -n tddc88-ht24-company1 -o jsonpath='{.items[0].metadata.name}')
        - echo "Waiting for ingress $INGRESS_NAME to be ready..."
        #- kubectl exec $POD_NAME_FE -n tddc88-ht24-company1 -- curl http://backend-service:5555/api
        #- kubectl wait --for=condition=ready ingress/$INGRESS_NAME -n tddc88-ht24-company1 --timeout=600s
        - sleep 40
        - kubectl apply -f k8s/allow-outbound-to-azure.yaml
        - kubectl describe ingress app-ingress -n $POD_NAMESPACE
        - kubectl get ingress -n $POD_NAMESPACE
        - kubectl get events -n $POD_NAMESPACE --sort-by='.metadata.creationTimestamp'
        - echo "Checking endpoint availability..."
        - kubectl get endpoints -n $POD_NAMESPACE
        - kubectl describe ingress app-ingress -n tddc88-ht24-company1
        #- kubectl logs $POD_NAME_FE -n tddc88-ht24-company1
        #- kubectl logs -f $POD_NAME -n tddc88-ht24-company1
        #- kubectl exec -it $POD_NAME_FE -n tddc88-ht24-company1 -- cat /etc/nginx/conf.d/default.conf
        #- kubectl get pods --all-namespaces -l app.kubernetes.io/name=ingress

status:
    stage: deploy
    image: bitnami/kubectl
    before_script:
        - kubectl version --output=yaml
        - kubectl config view
        - kubectl config get-contexts
        - kubectl config use-context tddc88-ht24/infrastructure:tddc88-ht24
    script:
        - kubectl config get-contexts
        - kubectl get pods
        - kubectl get pods --show-labels
        - kubectl get endpoints
        - kubectl get all
    variables:
        GIT_STRATEGY: none